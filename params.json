{"name":"PipesJs/Core","tagline":"Basic utilities for web streams","body":"# pipesjs\r\n\r\n`pipesjs` includes an evolving bunch of modules of utilities and helpers for [`web streams`](https://streams.spec.whatwg.org).\r\n\r\n******\r\n\r\n# pipes/ core\r\n\r\n## Contents\r\n\r\n - [About](#about)\r\n - [Installing](#installing)\r\n - [API Reference](#api-reference)\r\n\r\n## About\r\n\r\nThe `core` module contains some basic utility functions to make working with `web streams` a lot easier. Here's more about `Web Streams` from the [spec](https://streams.spec.whatwg.org) itself:\r\n\r\n > Large swathes of the web platform are built on streaming data: that is, data that is created, processed, and consumed in an incremental fashion, without ever reading all of it into memory. The Streams Standard provides a common set of APIs for creating and interfacing with such streaming data, embodied in readable streams, writable streams, and transform streams.\r\n\r\nThe spec is still evolving but has reached a fairly stable stage with a [reference implementation](https://github.com/whatwg/streams/tree/master/reference-implementation) as well. The API has almost been finalized and `Stream`s are coming to the web very soon!\r\n\r\nAt it's core, the API exposes three major components:\r\n\r\n - `ReadableStream` encapsulates a source producing values and emits them.\r\n - `TransformStream` are essentially `{ readable, writable}` pairs that take a function which can be used to transform the values flowing through it.\r\n - `WritableStream` encapsulates a sink that receives values and writes to it.\r\n\r\n `Stream`s are essentially data structures that handle sequential flow of values. You can split streams, merge them and connect them together in various ways. What's amazing is that, in most cases, they can handle [backpressure](https://streams.spec.whatwg.org/#pipe-chains) automatically, so you don't have to mess with the underlying details.\r\n\r\nFor further information, the spec is quite informative and easy to read. [Jake Archibald](https://github.com/jakearchibald) also wrote a great [blog post](https://jakearchibald.com/2016/streams-ftw/) on them.\r\n\r\n **Heads up:** If you're coming from `node` land, `web streams` are quite a lot different from `node streams` and incompatible with each other.\r\n\r\n## Installing\r\n\r\n### For browsers\r\n\r\nThe library depends on a [polyfill](https://github.com/creatorrr/web-stream-polyfill) for browsers that don't support `Stream` APIs yet (which as of now, is all of them), so make sure you include it in before including the library.\r\n\r\nYou can use either of the builds from the `dist` folder:\r\n\r\n```html\r\n    <script src=\"path/to/web-streams-polyfill.js\"></script>\r\n    <script src=\"path/to/pipes.core.js\"></script>\r\n```\r\n\r\nAnd in your code, all the functions will be available on the `window.Pipes` variable.\r\n\r\n```javascript\r\n\r\n    let { pipe, flatten } = window.Pipes;\r\n\r\n    flatten(/* some streams here */);\r\n```\r\n\r\n### For browserify users\r\n\r\nThe library has a [peer-dependency](https://nodejs.org/en/blog/npm/peer-dependencies/) on [web-streams-polyfill](https://github.com/creatorrr/web-stream-polyfill), so to install it:\r\n\r\n```bash\r\n\r\n    npm install web-streams-polyfill @pipes/core\r\n\r\n```\r\n\r\nThe library is split up into modules, so you can both require the whole library or only parts of it:\r\n\r\n```javascript\r\n\r\n    let { flatten } = require(\"@pipes/core\");\r\n    let merge = require(\"@pipes/core/merge\");\r\n```\r\n\r\n### For ES6 and Rollup users\r\n\r\nIf you want, you can directly import the es6 modules like so:\r\n\r\n```javascript\r\n\r\n    import pipes from \"@pipes/core/src\";\r\n    import { flatten } from \"@pipes/core/src\";\r\n    import flatten from \"@pipes/core/src/flatten\";\r\n```\r\n\r\n## API Reference\r\n\r\nThe library only consists of the following functions:\r\n\r\n -  [pipe](#pipe)\r\n -  [pipe.async](#pipeasync)\r\n -  [chain](#chain)\r\n -  [connect](#connect)\r\n -  [flatten](#flatten)\r\n -  [merge](#merge)\r\n -  [zip](#zip)\r\n -  [split](#split)\r\n\r\n### pipe\r\n\r\n```javascript\r\npipe (\r\n  Function | Generator Function,\r\n  Object {\r\n    init,   // value to initiate transform stream\r\n    writableStrategy,\r\n    readableStrategy    // instances of queuing strategies\r\n  }\r\n) -> TransformBlueprint // Constructor that returns transform stream\r\n```\r\n\r\n`pipe` function takes a transform function or generator and an opts object; returns a TransforBlueprint that can be used to create `transform streams`.\r\n\r\nIf a `Generator Function` is passed, it is consumed entirely on each transform call and results enqueud. Backpressure is handled automatically and if `stream` is cancelled, any live `generator` is gracefully shutdown. On shutdown, `generator` is sent `true` as a signal to prepare shutdown.\r\n\r\nIf the function doesn't return anything or returns `undefined`, nothing is written on the stream.\r\n\r\n```javascript\r\n\r\n// Setup\r\nlet createReadable = data => new ReadableStream({\r\n    start (controller) {\r\n      this.data = data || [1,2,3];\r\n\r\n      // Kickstart stream\r\n      controller.enqueue( this.data.pop() );\r\n    },\r\n    pull (controller) {\r\n      if ( !this.data.length )\r\n        return controller.close()\r\n\r\n      controller.enqueue( this.data.pop() );\r\n    }\r\n  }),\r\n  createWritable = () => new WritableStream({\r\n    write (chunk) {\r\n      console.log( chunk );\r\n    }\r\n  });\r\n\r\n// Pure funtion example\r\nlet negator = pipe( n => -n ),\r\n  rIn = createReadable(),\r\n  rOut;\r\n\r\nrOut = rIn.pipeThrough( new negator );  // -1, -2, -3\r\n\r\n\r\n// Basic generator example\r\nlet doubler = pipe( function* (v) {\r\n    yield v;\r\n    yield v;\r\n  }),\r\n  rIn = createReadable(),\r\n  rOut;\r\n\r\nrOut = rIn.pipeThrough( new doubler );  // 1, 1, 2, 2, 3, 3\r\n\r\n\r\n// Infinite generator example\r\n\r\nlet inf = pipe( function* (v) {\r\n    // Close on shutdown signal\r\n    while( !( yield v ));\r\n  }, {\r\n    init: 1\r\n  });\r\n\r\nnew inf;    // 1, 1, 1, 1...\r\n```\r\n\r\n### pipe.async\r\n\r\n```javascript\r\npipe.async (\r\n  Async Function,\r\n  Object {\r\n    init,   // value to initiate transform stream\r\n    writableStrategy,\r\n    readableStrategy    // instances of queuing strategies\r\n  }\r\n) -> TransformBlueprint // Constructor that returns transform stream\r\n```\r\n\r\n`pipe.async` function takes an async function and an opts object; returns a TransforBlueprint that can be used to create `transform streams`.\r\n\r\nIf an `Async Function` is passed, it is run on each transform call and results awaited and then enqueud. Backpressure is handled automatically and if `stream` is cancelled, any live `future`s is gracefully shutdown.\r\n\r\nIf the function doesn't return anything or returns `undefined`, nothing is written on the stream.\r\n\r\n```javascript\r\n\r\n// Basic async example\r\nlet serverTalker = pipe.async( async function (msg) {\r\n    let response = await sendToServer( msg );\r\n    return response;\r\n  }),\r\n  rIn = createReadable(),\r\n  rOut;\r\n\r\nrOut = rIn.pipeThrough( new serverTalker );  // {response}, {response}, {response}\r\n\r\n```\r\n\r\n### chain\r\n\r\n```javascript\r\nchain (\r\n  ...TransformStream()\r\n) -> { readable, writable }\r\n```\r\n\r\n`chain` takes any number of `transform streams` and chains them together and returns a `transform stream` that acts as a composition of the input streams.\r\n\r\n```javascript\r\n\r\n// Pure funtion example\r\nlet negator = pipe( n => -n ),\r\n  doubler = pipe( n => 2*n ),\r\n  composed = chain( new negator, new doubler ),\r\n  rIn = createReadable(),\r\n  rOut;\r\n\r\nrOut = rIn.pipeThrough( composed );  // -2, -4, -6\r\n\r\n```\r\n\r\n### connect\r\n\r\n```javascript\r\nconnect (\r\n  ReadableStream() | TransformStream(),\r\n  ...TransformStream(),\r\n  <Optional> WritableStream()\r\n) -> ReadableStream() | Promise()\r\n```\r\n\r\n`connect` takes any number of `transform streams` with an optional `readable` at the head and a `writable` at the tail. It connects them together by applying `pipeThrough` recursively and returns the resulting `readable` that acts as a composition of the input streams.\r\n\r\nIn case, a `writable` is passed at the tail, the resulting `readable` is `pipeTo`d and the resulting `promise` is returned.\r\n```javascript\r\n\r\nlet readable = createReadable(),\r\n  writable = createWritable(),\r\n  passThrough = pipe( k => k );\r\n\r\nlet promise = connect( readable, passThrough, writable );   // 1, 2, 3\r\n```\r\n\r\n### flatten\r\n\r\n```javascript\r\nflatten (\r\n  ...ReadableStream()\r\n) -> ReadableStream()\r\n```\r\n\r\n`flatten` takes any number of `readable streams` and returns a new `readable stream` with chunks enqueued as they are produced by the input streams, in order they are produced.\r\n\r\n```javascript\r\n\r\nlet r1 = createReadable([1,2,3]),\r\n  r2 = createReadable([4,5,6]),\r\n  writable = createWritable(),\r\n  flattened = flatten(r1,r2);\r\n\r\nflattened.pipeTo( writable );   // 1,4,2,5,3,6   (order depends on order received so may vary)\r\n```\r\n\r\n### merge\r\n\r\n```javascript\r\nmerge (\r\n  ...ReadableStream()\r\n) -> ReadableStream()\r\n```\r\n\r\n`merge` takes any number of `readable streams` and returns a new `readable stream` with arrays of chunks produced by all the input streams enqueued. It waits for all the streams to produce a value before grouping them together. Resulting stream closes when any of the input streams does.\r\n\r\n```javascript\r\n\r\nlet r1 = createReadable([1,2,3]),\r\n  r2 = createReadable([4,5,6,7]),\r\n  writable = createWritable(),\r\n  merged = merge(r1,r2);\r\n\r\nmerged.pipeTo( writable );   // [1,4], [2,5], [3,6]\r\n```\r\n\r\n### zip\r\n\r\n```javascript\r\nzip (\r\n  ReadableStream()<Function>,\r\n  ...ReadableStream()\r\n) -> ReadableStream()\r\n```\r\n\r\n`zip` takes a `readable` producing functions and any number of `readable streams` and returns a new `readable stream` with the results of functions applied to corresponding chunks produced by the rest input streams enqueued. It waits for all the streams to produce a value before zipping them together. Resulting stream closes when any of the input streams does.\r\n\r\n```javascript\r\n\r\nlet add = (a, b) => a + b,\r\n  rFn = createReadable([add,add,add]),\r\n  r1 = createReadable([1,2,3]),\r\n  r2 = createReadable([4,5,6]),\r\n  writable = createWritable(),\r\n  zipped = zip(rFn,r1,r2);\r\n\r\nzipped.pipeTo( writable );   // 5, 7, 9\r\n```\r\n\r\n### split\r\n\r\n```javascript\r\nsplit (\r\n  ReadableStream(),\r\n  Int (default=2)\r\n) -> [...ReadableStream()]\r\n```\r\n\r\n`split` takes a `readable` and a number of branches, returns an array of `readable`s that are copies of the original. `ReadableStream().tee` is called repeatedly to produce the branches.\r\n\r\nTo cancel the original stream, all the branches must be canceled first. Hence the resulting branches have an added `cancelAll()` method that cancels all the branches and the original stream.\r\n\r\n```javascript\r\n\r\nlet readable = createReadable([1,2,3]),\r\n  [r1, r2] = split( readable ),\r\n  w1 = createWritable(),\r\n  w2 = createWritable();\r\n\r\nr1.pipeTo( w1 );   // 1, 2, 3\r\nr2.pipeTo( w2 );   // 1, 2, 3\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}